{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pywt\n",
    "import matplotlib.pyplot as pl\n",
    "import tensorflow as tf\n",
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model\n",
    "from keras import regularizers\n",
    "import keras.layers as kl\n",
    "from bokeh.plotting import output_file, figure, show\n",
    "import keras as kr\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "import pandas_datareader.data as pdr\n",
    "import fix_yahoo_finance as fix\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "fix.pdr_override()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 downloaded\n"
     ]
    }
   ],
   "source": [
    "class GetData:\n",
    "    def __init__(self, ticker, start, end):\n",
    "        self.ticker = ticker\n",
    "        self.start = start\n",
    "        self.end = end\n",
    "\n",
    "    # get stock data\n",
    "    def get_stock_data(self):\n",
    "        stock_data = pdr.get_data_yahoo(self.ticker, self.start, self.end)\n",
    "        stock_data.to_csv(\"stock_data.csv\")\n",
    "\n",
    "    # get twitter data\n",
    "    # do your code here!\n",
    "\n",
    "    # get news data\n",
    "    # do your code here!\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    data = GetData(\"AAPL\", \"2000-01-01\", \"2018-10-01\")\n",
    "    data.get_stock_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PreProcessing:\n",
    "    def __init__(self, split, feature_split):\n",
    "        self.split = split\n",
    "        self.feature_split = feature_split\n",
    "        self.stock_data = pd.read_csv(\"stock_data.csv\")\n",
    "\n",
    "    # wavelet transform and create autoencoder data\n",
    "    def make_wavelet_train(self):\n",
    "        train_data = []\n",
    "        test_data = []\n",
    "        log_train_data = []\n",
    "        for i in range((len(self.stock_data)//10)*10 - 11):\n",
    "            train = []\n",
    "            log_ret = []\n",
    "            for j in range(1, 6):\n",
    "                x = np.array(self.stock_data.iloc[i: i + 11, j])\n",
    "                (ca, cd) = pywt.dwt(x, \"haar\")\n",
    "                cat = pywt.threshold(ca, np.std(ca), mode=\"soft\")\n",
    "                cdt = pywt.threshold(cd, np.std(cd), mode=\"soft\")\n",
    "                tx = pywt.idwt(cat, cdt, \"haar\")\n",
    "                log = np.diff(np.log(tx))*100\n",
    "                macd = np.mean(x[5:]) - np.mean(x)\n",
    "                # ma = np.mean(x)\n",
    "                sd = np.std(x)\n",
    "                log_ret = np.append(log_ret, log)\n",
    "                x_tech = np.append(macd*10, sd)\n",
    "                train = np.append(train, x_tech)\n",
    "            train_data.append(train)\n",
    "            log_train_data.append(log_ret)\n",
    "        trained = pd.DataFrame(train_data)\n",
    "        trained.to_csv(\"preprocessing/indicators.csv\")\n",
    "        log_train = pd.DataFrame(log_train_data, index=None)\n",
    "        log_train.to_csv(\"preprocessing/log_train.csv\")\n",
    "        # auto_train = pd.DataFrame(train_data[0:800])\n",
    "        # auto_test = pd.DataFrame(train_data[801:1000])\n",
    "        # auto_train.to_csv(\"auto_train.csv\")\n",
    "        # auto_test.to_csv(\"auto_test.csv\")\n",
    "        rbm_train = pd.DataFrame(log_train_data[0:int(self.split*self.feature_split*len(log_train_data))], index=None)\n",
    "        rbm_train.to_csv(\"preprocessing/rbm_train.csv\")\n",
    "        rbm_test = pd.DataFrame(log_train_data[int(self.split*self.feature_split*len(log_train_data))+1:\n",
    "                                               int(self.feature_split*len(log_train_data))])\n",
    "        rbm_test.to_csv(\"preprocessing/rbm_test.csv\")\n",
    "        for i in range((len(self.stock_data) // 10) * 10 - 11):\n",
    "            y = 100*np.log(self.stock_data.iloc[i + 11, 5] / self.stock_data.iloc[i + 10, 5])\n",
    "            test_data.append(y)\n",
    "        test = pd.DataFrame(test_data)\n",
    "        test.to_csv(\"preprocessing/test_data.csv\")\n",
    "\n",
    "    def make_test_data(self):\n",
    "        test_stock = []\n",
    "        # stock_data_test = pd.read_csv(\"stock_data_test.csv\", index_col=0)\n",
    "\n",
    "        for i in range((len(self.stock_data) // 10) * 10 - 11):\n",
    "            l = self.stock_data.iloc[i+11, 5]\n",
    "            test_stock.append(l)\n",
    "            test = pd.DataFrame(test_stock)\n",
    "            test.to_csv(\"preprocessing/test_stock.csv\")\n",
    "\n",
    "        stock_test_data = np.array(test_stock)[int(self.feature_split*len(test_stock) +\n",
    "                                               self.split*(1-self.feature_split)*len(test_stock)):]\n",
    "        stock = pd.DataFrame(stock_test_data, index=None)\n",
    "        stock.to_csv(\"stock_data_test.csv\")\n",
    "\n",
    "        # print(train_data[1:5])\n",
    "        # print(test_data[1:5])\n",
    "        # plt.plot(train_data[1])\n",
    "        # plt.show()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    preprocess = PreProcessing(0.8, 0.25)\n",
    "    preprocess.make_wavelet_train()\n",
    "    preprocess.make_test_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "939/939 [==============================] - 3s 3ms/step - loss: 16.7614\n",
      "Epoch 2/300\n",
      "939/939 [==============================] - 0s 221us/step - loss: 16.4917\n",
      "Epoch 3/300\n",
      "939/939 [==============================] - 0s 228us/step - loss: 16.1592\n",
      "Epoch 4/300\n",
      "939/939 [==============================] - 0s 216us/step - loss: 15.9250\n",
      "Epoch 5/300\n",
      "939/939 [==============================] - 0s 218us/step - loss: 15.8084\n",
      "Epoch 6/300\n",
      "939/939 [==============================] - 0s 220us/step - loss: 15.7550\n",
      "Epoch 7/300\n",
      "939/939 [==============================] - 0s 220us/step - loss: 15.7142\n",
      "Epoch 8/300\n",
      "939/939 [==============================] - 0s 222us/step - loss: 15.6765\n",
      "Epoch 9/300\n",
      "939/939 [==============================] - 0s 218us/step - loss: 15.6468\n",
      "Epoch 10/300\n",
      "939/939 [==============================] - 0s 222us/step - loss: 15.6214\n",
      "Epoch 11/300\n",
      "939/939 [==============================] - 0s 327us/step - loss: 15.5891\n",
      "Epoch 12/300\n",
      "939/939 [==============================] - 0s 281us/step - loss: 15.5612\n",
      "Epoch 13/300\n",
      "939/939 [==============================] - 0s 276us/step - loss: 15.5416\n",
      "Epoch 14/300\n",
      "939/939 [==============================] - 0s 288us/step - loss: 15.5197\n",
      "Epoch 15/300\n",
      "939/939 [==============================] - 0s 247us/step - loss: 15.5020\n",
      "Epoch 16/300\n",
      "939/939 [==============================] - 0s 287us/step - loss: 15.4837\n",
      "Epoch 17/300\n",
      "939/939 [==============================] - 0s 286us/step - loss: 15.4698\n",
      "Epoch 18/300\n",
      "939/939 [==============================] - 0s 302us/step - loss: 15.4553\n",
      "Epoch 19/300\n",
      "939/939 [==============================] - 0s 279us/step - loss: 15.4449\n",
      "Epoch 20/300\n",
      "939/939 [==============================] - 0s 270us/step - loss: 15.4349\n",
      "Epoch 21/300\n",
      "939/939 [==============================] - 0s 318us/step - loss: 15.4257\n",
      "Epoch 22/300\n",
      "939/939 [==============================] - 0s 235us/step - loss: 15.4196\n",
      "Epoch 23/300\n",
      "939/939 [==============================] - 0s 221us/step - loss: 15.4137\n",
      "Epoch 24/300\n",
      "939/939 [==============================] - 0s 246us/step - loss: 15.4034\n",
      "Epoch 25/300\n",
      "939/939 [==============================] - 0s 241us/step - loss: 15.3959\n",
      "Epoch 26/300\n",
      "939/939 [==============================] - 0s 224us/step - loss: 15.3952\n",
      "Epoch 27/300\n",
      "939/939 [==============================] - 0s 222us/step - loss: 15.3901\n",
      "Epoch 28/300\n",
      "939/939 [==============================] - 0s 220us/step - loss: 15.3835\n",
      "Epoch 29/300\n",
      "939/939 [==============================] - 0s 220us/step - loss: 15.3782\n",
      "Epoch 30/300\n",
      "939/939 [==============================] - 0s 284us/step - loss: 15.3768\n",
      "Epoch 31/300\n",
      "939/939 [==============================] - 0s 288us/step - loss: 15.3727\n",
      "Epoch 32/300\n",
      "939/939 [==============================] - 0s 280us/step - loss: 15.3696\n",
      "Epoch 33/300\n",
      "939/939 [==============================] - 0s 268us/step - loss: 15.3686\n",
      "Epoch 34/300\n",
      "939/939 [==============================] - 0s 326us/step - loss: 15.3658\n",
      "Epoch 35/300\n",
      "939/939 [==============================] - 0s 301us/step - loss: 15.3634\n",
      "Epoch 36/300\n",
      "939/939 [==============================] - 0s 320us/step - loss: 15.3704\n",
      "Epoch 37/300\n",
      "939/939 [==============================] - 0s 256us/step - loss: 15.3644\n",
      "Epoch 38/300\n",
      "939/939 [==============================] - 0s 333us/step - loss: 15.3621\n",
      "Epoch 39/300\n",
      "939/939 [==============================] - 0s 305us/step - loss: 15.3572\n",
      "Epoch 40/300\n",
      "939/939 [==============================] - 0s 284us/step - loss: 15.3520\n",
      "Epoch 41/300\n",
      "939/939 [==============================] - 0s 218us/step - loss: 15.3496\n",
      "Epoch 42/300\n",
      "939/939 [==============================] - 0s 220us/step - loss: 15.3465\n",
      "Epoch 43/300\n",
      "939/939 [==============================] - 0s 251us/step - loss: 15.3440\n",
      "Epoch 44/300\n",
      "939/939 [==============================] - 0s 361us/step - loss: 15.3418\n",
      "Epoch 45/300\n",
      "939/939 [==============================] - 0s 306us/step - loss: 15.3419\n",
      "Epoch 46/300\n",
      "939/939 [==============================] - 0s 227us/step - loss: 15.3388\n",
      "Epoch 47/300\n",
      "939/939 [==============================] - 0s 225us/step - loss: 15.3399\n",
      "Epoch 48/300\n",
      "939/939 [==============================] - 0s 233us/step - loss: 15.3374\n",
      "Epoch 49/300\n",
      "939/939 [==============================] - 0s 225us/step - loss: 15.3420\n",
      "Epoch 50/300\n",
      "939/939 [==============================] - 0s 222us/step - loss: 15.3340\n",
      "Epoch 51/300\n",
      "939/939 [==============================] - 0s 312us/step - loss: 15.3367\n",
      "Epoch 52/300\n",
      "939/939 [==============================] - 0s 325us/step - loss: 15.3317\n",
      "Epoch 53/300\n",
      "939/939 [==============================] - 0s 335us/step - loss: 15.3333\n",
      "Epoch 54/300\n",
      "939/939 [==============================] - 0s 396us/step - loss: 15.3295\n",
      "Epoch 55/300\n",
      "939/939 [==============================] - 0s 280us/step - loss: 15.3281\n",
      "Epoch 56/300\n",
      "939/939 [==============================] - 0s 343us/step - loss: 15.3260\n",
      "Epoch 57/300\n",
      "939/939 [==============================] - 0s 268us/step - loss: 15.3256\n",
      "Epoch 58/300\n",
      "939/939 [==============================] - 0s 292us/step - loss: 15.3242\n",
      "Epoch 59/300\n",
      "939/939 [==============================] - 0s 367us/step - loss: 15.3248\n",
      "Epoch 60/300\n",
      "939/939 [==============================] - 0s 387us/step - loss: 15.3233\n",
      "Epoch 61/300\n",
      "939/939 [==============================] - 0s 294us/step - loss: 15.3202\n",
      "Epoch 62/300\n",
      "939/939 [==============================] - 0s 224us/step - loss: 15.3190\n",
      "Epoch 63/300\n",
      "939/939 [==============================] - 0s 232us/step - loss: 15.3199\n",
      "Epoch 64/300\n",
      "939/939 [==============================] - 0s 284us/step - loss: 15.3193\n",
      "Epoch 65/300\n",
      "939/939 [==============================] - 0s 284us/step - loss: 15.3160\n",
      "Epoch 66/300\n",
      "939/939 [==============================] - 0s 245us/step - loss: 15.3201\n",
      "Epoch 67/300\n",
      "939/939 [==============================] - 0s 227us/step - loss: 15.3149\n",
      "Epoch 68/300\n",
      "939/939 [==============================] - 0s 223us/step - loss: 15.3122\n",
      "Epoch 69/300\n",
      "939/939 [==============================] - 0s 269us/step - loss: 15.3103\n",
      "Epoch 70/300\n",
      "939/939 [==============================] - 0s 251us/step - loss: 15.31050s - loss: \n",
      "Epoch 71/300\n",
      "939/939 [==============================] - 0s 218us/step - loss: 15.3101\n",
      "Epoch 72/300\n",
      "939/939 [==============================] - 0s 216us/step - loss: 15.30870s - loss: 1\n",
      "Epoch 73/300\n",
      "939/939 [==============================] - 0s 238us/step - loss: 15.3070\n",
      "Epoch 74/300\n",
      "939/939 [==============================] - 0s 314us/step - loss: 15.3074\n",
      "Epoch 75/300\n",
      "939/939 [==============================] - 0s 296us/step - loss: 15.3057\n",
      "Epoch 76/300\n",
      "939/939 [==============================] - 0s 287us/step - loss: 15.3038\n",
      "Epoch 77/300\n",
      "939/939 [==============================] - 0s 224us/step - loss: 15.3048\n",
      "Epoch 78/300\n",
      "939/939 [==============================] - 0s 213us/step - loss: 15.3049\n",
      "Epoch 79/300\n",
      "939/939 [==============================] - 0s 235us/step - loss: 15.3043\n",
      "Epoch 80/300\n",
      "939/939 [==============================] - 0s 224us/step - loss: 15.3017\n",
      "Epoch 81/300\n",
      "939/939 [==============================] - 0s 212us/step - loss: 15.3006\n",
      "Epoch 82/300\n",
      "939/939 [==============================] - 0s 222us/step - loss: 15.2994\n",
      "Epoch 83/300\n",
      "939/939 [==============================] - 0s 219us/step - loss: 15.3003\n",
      "Epoch 84/300\n",
      "939/939 [==============================] - 0s 218us/step - loss: 15.2991\n",
      "Epoch 85/300\n",
      "939/939 [==============================] - 0s 243us/step - loss: 15.3412\n",
      "Epoch 86/300\n",
      "939/939 [==============================] - 0s 326us/step - loss: 15.3225\n",
      "Epoch 87/300\n",
      "939/939 [==============================] - 0s 269us/step - loss: 15.3218\n",
      "Epoch 88/300\n",
      "939/939 [==============================] - 0s 217us/step - loss: 15.3099\n",
      "Epoch 89/300\n",
      "939/939 [==============================] - 0s 217us/step - loss: 15.3022\n",
      "Epoch 90/300\n",
      "939/939 [==============================] - 0s 236us/step - loss: 15.2920\n",
      "Epoch 91/300\n",
      "939/939 [==============================] - 0s 239us/step - loss: 15.2884\n",
      "Epoch 92/300\n",
      "939/939 [==============================] - 0s 216us/step - loss: 15.2896\n",
      "Epoch 93/300\n",
      "939/939 [==============================] - 0s 216us/step - loss: 15.2852\n",
      "Epoch 94/300\n",
      "939/939 [==============================] - 0s 218us/step - loss: 15.2861\n",
      "Epoch 95/300\n",
      "939/939 [==============================] - 0s 215us/step - loss: 15.2846\n",
      "Epoch 96/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "939/939 [==============================] - 0s 224us/step - loss: 15.2830\n",
      "Epoch 97/300\n",
      "939/939 [==============================] - 0s 213us/step - loss: 15.2816\n",
      "Epoch 98/300\n",
      "939/939 [==============================] - 0s 214us/step - loss: 15.2811\n",
      "Epoch 99/300\n",
      "939/939 [==============================] - 0s 215us/step - loss: 15.2811\n",
      "Epoch 100/300\n",
      "939/939 [==============================] - 0s 214us/step - loss: 15.2817\n",
      "Epoch 101/300\n",
      "939/939 [==============================] - 0s 214us/step - loss: 15.2798\n",
      "Epoch 102/300\n",
      "939/939 [==============================] - 0s 215us/step - loss: 15.2776\n",
      "Epoch 103/300\n",
      "939/939 [==============================] - 0s 216us/step - loss: 15.2770\n",
      "Epoch 104/300\n",
      "939/939 [==============================] - 0s 219us/step - loss: 15.2778\n",
      "Epoch 105/300\n",
      "939/939 [==============================] - 0s 216us/step - loss: 15.2773\n",
      "Epoch 106/300\n",
      "939/939 [==============================] - 0s 213us/step - loss: 15.2772\n",
      "Epoch 107/300\n",
      "939/939 [==============================] - 0s 217us/step - loss: 15.2744\n",
      "Epoch 108/300\n",
      "939/939 [==============================] - 0s 216us/step - loss: 15.2743\n",
      "Epoch 109/300\n",
      "939/939 [==============================] - 0s 215us/step - loss: 15.2813\n",
      "Epoch 110/300\n",
      "939/939 [==============================] - 0s 229us/step - loss: 15.2842\n",
      "Epoch 111/300\n",
      "939/939 [==============================] - 0s 214us/step - loss: 15.2791\n",
      "Epoch 112/300\n",
      "939/939 [==============================] - 0s 215us/step - loss: 15.2745\n",
      "Epoch 113/300\n",
      "939/939 [==============================] - 0s 268us/step - loss: 15.2706\n",
      "Epoch 114/300\n",
      "939/939 [==============================] - 0s 339us/step - loss: 15.2696\n",
      "Epoch 115/300\n",
      "939/939 [==============================] - 0s 223us/step - loss: 15.2878\n",
      "Epoch 116/300\n",
      "939/939 [==============================] - 0s 214us/step - loss: 15.2790\n",
      "Epoch 117/300\n",
      "939/939 [==============================] - 0s 223us/step - loss: 15.2760\n",
      "Epoch 118/300\n",
      "939/939 [==============================] - 0s 325us/step - loss: 15.2750\n",
      "Epoch 119/300\n",
      "939/939 [==============================] - 0s 307us/step - loss: 15.2705\n",
      "Epoch 120/300\n",
      "939/939 [==============================] - 0s 217us/step - loss: 15.2708\n",
      "Epoch 121/300\n",
      "939/939 [==============================] - 0s 214us/step - loss: 15.2690\n",
      "Epoch 122/300\n",
      "939/939 [==============================] - 0s 271us/step - loss: 15.2679\n",
      "Epoch 123/300\n",
      "939/939 [==============================] - 0s 325us/step - loss: 15.2683\n",
      "Epoch 124/300\n",
      "939/939 [==============================] - 0s 299us/step - loss: 15.2683\n",
      "Epoch 125/300\n",
      "939/939 [==============================] - 0s 225us/step - loss: 15.2667\n",
      "Epoch 126/300\n",
      "939/939 [==============================] - 0s 220us/step - loss: 15.2652\n",
      "Epoch 127/300\n",
      "939/939 [==============================] - 0s 230us/step - loss: 15.2666\n",
      "Epoch 128/300\n",
      "939/939 [==============================] - 0s 225us/step - loss: 15.2674\n",
      "Epoch 129/300\n",
      "939/939 [==============================] - 0s 213us/step - loss: 15.2653\n",
      "Epoch 130/300\n",
      "939/939 [==============================] - 0s 213us/step - loss: 15.2733\n",
      "Epoch 131/300\n",
      "939/939 [==============================] - 0s 219us/step - loss: 15.2722\n",
      "Epoch 132/300\n",
      "939/939 [==============================] - 0s 220us/step - loss: 15.2683\n",
      "Epoch 133/300\n",
      "939/939 [==============================] - 0s 219us/step - loss: 15.2674\n",
      "Epoch 134/300\n",
      "939/939 [==============================] - 0s 215us/step - loss: 15.2659\n",
      "Epoch 135/300\n",
      "939/939 [==============================] - 0s 215us/step - loss: 15.2649\n",
      "Epoch 136/300\n",
      "939/939 [==============================] - 0s 212us/step - loss: 15.2656\n",
      "Epoch 137/300\n",
      "939/939 [==============================] - 0s 218us/step - loss: 15.2665\n",
      "Epoch 138/300\n",
      "939/939 [==============================] - 0s 215us/step - loss: 15.2647\n",
      "Epoch 139/300\n",
      "939/939 [==============================] - 0s 216us/step - loss: 15.2646\n",
      "Epoch 140/300\n",
      "939/939 [==============================] - 0s 217us/step - loss: 15.2627\n",
      "Epoch 141/300\n",
      "939/939 [==============================] - 0s 233us/step - loss: 15.2647\n",
      "Epoch 142/300\n",
      "939/939 [==============================] - 0s 305us/step - loss: 15.2629\n",
      "Epoch 143/300\n",
      "939/939 [==============================] - 0s 221us/step - loss: 15.2637\n",
      "Epoch 144/300\n",
      "939/939 [==============================] - 0s 230us/step - loss: 15.2659\n",
      "Epoch 145/300\n",
      "939/939 [==============================] - 0s 218us/step - loss: 15.2617\n",
      "Epoch 146/300\n",
      "939/939 [==============================] - 0s 221us/step - loss: 15.2606\n",
      "Epoch 147/300\n",
      "939/939 [==============================] - 0s 235us/step - loss: 15.2603\n",
      "Epoch 148/300\n",
      "939/939 [==============================] - 0s 216us/step - loss: 15.2619\n",
      "Epoch 149/300\n",
      "939/939 [==============================] - 0s 216us/step - loss: 15.2622\n",
      "Epoch 150/300\n",
      "939/939 [==============================] - 0s 217us/step - loss: 15.2609\n",
      "Epoch 151/300\n",
      "939/939 [==============================] - 0s 217us/step - loss: 15.2604\n",
      "Epoch 152/300\n",
      "939/939 [==============================] - 0s 215us/step - loss: 15.2598\n",
      "Epoch 153/300\n",
      "939/939 [==============================] - 0s 216us/step - loss: 15.2604\n",
      "Epoch 154/300\n",
      "939/939 [==============================] - 0s 253us/step - loss: 15.2651\n",
      "Epoch 155/300\n",
      "939/939 [==============================] - 0s 224us/step - loss: 15.2606\n",
      "Epoch 156/300\n",
      "939/939 [==============================] - 0s 228us/step - loss: 15.2614\n",
      "Epoch 157/300\n",
      "939/939 [==============================] - 0s 238us/step - loss: 15.2595\n",
      "Epoch 158/300\n",
      "939/939 [==============================] - 0s 215us/step - loss: 15.2589\n",
      "Epoch 159/300\n",
      "939/939 [==============================] - 0s 215us/step - loss: 15.2596\n",
      "Epoch 160/300\n",
      "939/939 [==============================] - 0s 229us/step - loss: 15.2780\n",
      "Epoch 161/300\n",
      "939/939 [==============================] - 0s 215us/step - loss: 15.2682\n",
      "Epoch 162/300\n",
      "939/939 [==============================] - 0s 213us/step - loss: 15.2626\n",
      "Epoch 163/300\n",
      "939/939 [==============================] - 0s 216us/step - loss: 15.2629\n",
      "Epoch 164/300\n",
      "939/939 [==============================] - 0s 260us/step - loss: 15.2617\n",
      "Epoch 165/300\n",
      "939/939 [==============================] - 0s 330us/step - loss: 15.2594\n",
      "Epoch 166/300\n",
      "939/939 [==============================] - 0s 305us/step - loss: 15.2581\n",
      "Epoch 167/300\n",
      "939/939 [==============================] - 0s 219us/step - loss: 15.2591\n",
      "Epoch 168/300\n",
      "939/939 [==============================] - 0s 214us/step - loss: 15.2561\n",
      "Epoch 169/300\n",
      "939/939 [==============================] - 0s 230us/step - loss: 15.2546\n",
      "Epoch 170/300\n",
      "939/939 [==============================] - 0s 230us/step - loss: 15.2543\n",
      "Epoch 171/300\n",
      "939/939 [==============================] - 0s 214us/step - loss: 15.2550\n",
      "Epoch 172/300\n",
      "939/939 [==============================] - 0s 214us/step - loss: 15.2551\n",
      "Epoch 173/300\n",
      "939/939 [==============================] - 0s 215us/step - loss: 15.2554\n",
      "Epoch 174/300\n",
      "939/939 [==============================] - 0s 223us/step - loss: 15.2534\n",
      "Epoch 175/300\n",
      "939/939 [==============================] - 0s 222us/step - loss: 15.2548\n",
      "Epoch 176/300\n",
      "939/939 [==============================] - 0s 227us/step - loss: 15.2590\n",
      "Epoch 177/300\n",
      "939/939 [==============================] - 0s 223us/step - loss: 15.2549\n",
      "Epoch 178/300\n",
      "939/939 [==============================] - 0s 221us/step - loss: 15.2561\n",
      "Epoch 179/300\n",
      "939/939 [==============================] - 0s 215us/step - loss: 15.2537\n",
      "Epoch 180/300\n",
      "939/939 [==============================] - 0s 215us/step - loss: 15.2585\n",
      "Epoch 181/300\n",
      "939/939 [==============================] - 0s 218us/step - loss: 15.2661\n",
      "Epoch 182/300\n",
      "939/939 [==============================] - 0s 299us/step - loss: 15.2595\n",
      "Epoch 183/300\n",
      "939/939 [==============================] - 0s 313us/step - loss: 15.2584\n",
      "Epoch 184/300\n",
      "939/939 [==============================] - 0s 307us/step - loss: 15.2553\n",
      "Epoch 185/300\n",
      "939/939 [==============================] - 0s 256us/step - loss: 15.2569\n",
      "Epoch 186/300\n",
      "939/939 [==============================] - 0s 321us/step - loss: 15.2571\n",
      "Epoch 187/300\n",
      "939/939 [==============================] - 0s 283us/step - loss: 15.2545\n",
      "Epoch 188/300\n",
      "939/939 [==============================] - 0s 218us/step - loss: 15.2523\n",
      "Epoch 189/300\n",
      "939/939 [==============================] - 0s 217us/step - loss: 15.2536\n",
      "Epoch 190/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "939/939 [==============================] - 0s 282us/step - loss: 15.2534\n",
      "Epoch 191/300\n",
      "939/939 [==============================] - 0s 236us/step - loss: 15.2509\n",
      "Epoch 192/300\n",
      "939/939 [==============================] - 0s 213us/step - loss: 15.2556\n",
      "Epoch 193/300\n",
      "939/939 [==============================] - 0s 221us/step - loss: 15.2560\n",
      "Epoch 194/300\n",
      "939/939 [==============================] - 0s 235us/step - loss: 15.2777\n",
      "Epoch 195/300\n",
      "939/939 [==============================] - 0s 341us/step - loss: 15.2574\n",
      "Epoch 196/300\n",
      "939/939 [==============================] - 0s 220us/step - loss: 15.2535\n",
      "Epoch 197/300\n",
      "939/939 [==============================] - 0s 223us/step - loss: 15.25450s - loss: 13.37\n",
      "Epoch 198/300\n",
      "939/939 [==============================] - 0s 216us/step - loss: 15.2511\n",
      "Epoch 199/300\n",
      "939/939 [==============================] - 0s 242us/step - loss: 15.2513\n",
      "Epoch 200/300\n",
      "939/939 [==============================] - 0s 225us/step - loss: 15.2531\n",
      "Epoch 201/300\n",
      "939/939 [==============================] - 0s 211us/step - loss: 15.2522\n",
      "Epoch 202/300\n",
      "939/939 [==============================] - 0s 228us/step - loss: 15.2521\n",
      "Epoch 203/300\n",
      "939/939 [==============================] - 0s 211us/step - loss: 15.2514\n",
      "Epoch 204/300\n",
      "939/939 [==============================] - 0s 220us/step - loss: 15.2513\n",
      "Epoch 205/300\n",
      "939/939 [==============================] - 0s 215us/step - loss: 15.2520\n",
      "Epoch 206/300\n",
      "939/939 [==============================] - 0s 217us/step - loss: 15.2529\n",
      "Epoch 207/300\n",
      "939/939 [==============================] - 0s 216us/step - loss: 15.2519\n",
      "Epoch 208/300\n",
      "939/939 [==============================] - 0s 216us/step - loss: 15.2505\n",
      "Epoch 209/300\n",
      "939/939 [==============================] - 0s 215us/step - loss: 15.2479\n",
      "Epoch 210/300\n",
      "939/939 [==============================] - 0s 216us/step - loss: 15.2480\n",
      "Epoch 211/300\n",
      "939/939 [==============================] - 0s 288us/step - loss: 15.2465\n",
      "Epoch 212/300\n",
      "939/939 [==============================] - 0s 302us/step - loss: 15.2542\n",
      "Epoch 213/300\n",
      "939/939 [==============================] - 0s 218us/step - loss: 15.2490\n",
      "Epoch 214/300\n",
      "939/939 [==============================] - 0s 212us/step - loss: 15.2484\n",
      "Epoch 215/300\n",
      "939/939 [==============================] - 0s 216us/step - loss: 15.2476\n",
      "Epoch 216/300\n",
      "939/939 [==============================] - 0s 254us/step - loss: 15.2654\n",
      "Epoch 217/300\n",
      "939/939 [==============================] - 0s 344us/step - loss: 15.2537\n",
      "Epoch 218/300\n",
      "939/939 [==============================] - 0s 218us/step - loss: 15.2494\n",
      "Epoch 219/300\n",
      "939/939 [==============================] - 0s 224us/step - loss: 15.2493\n",
      "Epoch 220/300\n",
      "939/939 [==============================] - 0s 254us/step - loss: 15.2499\n",
      "Epoch 221/300\n",
      "939/939 [==============================] - 0s 227us/step - loss: 15.2467\n",
      "Epoch 222/300\n",
      "939/939 [==============================] - 0s 213us/step - loss: 15.2485\n",
      "Epoch 223/300\n",
      "939/939 [==============================] - 0s 213us/step - loss: 15.2475\n",
      "Epoch 224/300\n",
      "939/939 [==============================] - 0s 220us/step - loss: 15.2463\n",
      "Epoch 225/300\n",
      "939/939 [==============================] - 0s 220us/step - loss: 15.2454\n",
      "Epoch 226/300\n",
      "939/939 [==============================] - 0s 221us/step - loss: 15.2455\n",
      "Epoch 227/300\n",
      "939/939 [==============================] - 0s 326us/step - loss: 15.2528\n",
      "Epoch 228/300\n",
      "939/939 [==============================] - 0s 307us/step - loss: 15.2822\n",
      "Epoch 229/300\n",
      "939/939 [==============================] - 0s 237us/step - loss: 15.2620\n",
      "Epoch 230/300\n",
      "939/939 [==============================] - 0s 218us/step - loss: 15.2684\n",
      "Epoch 231/300\n",
      "939/939 [==============================] - 0s 317us/step - loss: 15.2540\n",
      "Epoch 232/300\n",
      "939/939 [==============================] - 0s 309us/step - loss: 15.2505\n",
      "Epoch 233/300\n",
      "939/939 [==============================] - 0s 252us/step - loss: 15.2473\n",
      "Epoch 234/300\n",
      "939/939 [==============================] - 0s 219us/step - loss: 15.2461\n",
      "Epoch 235/300\n",
      "939/939 [==============================] - 0s 212us/step - loss: 15.2458\n",
      "Epoch 236/300\n",
      "939/939 [==============================] - 0s 247us/step - loss: 15.2450\n",
      "Epoch 237/300\n",
      "939/939 [==============================] - 0s 222us/step - loss: 15.2443\n",
      "Epoch 238/300\n",
      "939/939 [==============================] - 0s 262us/step - loss: 15.2466\n",
      "Epoch 239/300\n",
      "939/939 [==============================] - 0s 340us/step - loss: 15.2483\n",
      "Epoch 240/300\n",
      "939/939 [==============================] - 0s 230us/step - loss: 15.2460\n",
      "Epoch 241/300\n",
      "939/939 [==============================] - 0s 268us/step - loss: 15.2445\n",
      "Epoch 242/300\n",
      "939/939 [==============================] - 0s 338us/step - loss: 15.2429\n",
      "Epoch 243/300\n",
      "939/939 [==============================] - 0s 303us/step - loss: 15.2419\n",
      "Epoch 244/300\n",
      "939/939 [==============================] - 0s 254us/step - loss: 15.2410\n",
      "Epoch 245/300\n",
      "939/939 [==============================] - 0s 217us/step - loss: 15.2417\n",
      "Epoch 246/300\n",
      "939/939 [==============================] - 0s 295us/step - loss: 15.2418\n",
      "Epoch 247/300\n",
      "939/939 [==============================] - 0s 308us/step - loss: 15.2416\n",
      "Epoch 248/300\n",
      "939/939 [==============================] - 0s 218us/step - loss: 15.2426\n",
      "Epoch 249/300\n",
      "939/939 [==============================] - 0s 215us/step - loss: 15.2445\n",
      "Epoch 250/300\n",
      "939/939 [==============================] - 0s 249us/step - loss: 15.2427\n",
      "Epoch 251/300\n",
      "939/939 [==============================] - 0s 253us/step - loss: 15.2426\n",
      "Epoch 252/300\n",
      "939/939 [==============================] - 0s 214us/step - loss: 15.2414\n",
      "Epoch 253/300\n",
      "939/939 [==============================] - 0s 219us/step - loss: 15.2413\n",
      "Epoch 254/300\n",
      "939/939 [==============================] - 0s 330us/step - loss: 15.2451\n",
      "Epoch 255/300\n",
      "939/939 [==============================] - 0s 223us/step - loss: 15.2431\n",
      "Epoch 256/300\n",
      "939/939 [==============================] - 0s 313us/step - loss: 15.2411\n",
      "Epoch 257/300\n",
      "939/939 [==============================] - 0s 277us/step - loss: 15.2400\n",
      "Epoch 258/300\n",
      "939/939 [==============================] - 0s 218us/step - loss: 15.2422\n",
      "Epoch 259/300\n",
      "939/939 [==============================] - 0s 223us/step - loss: 15.2425\n",
      "Epoch 260/300\n",
      "939/939 [==============================] - 0s 274us/step - loss: 15.2433\n",
      "Epoch 261/300\n",
      "939/939 [==============================] - 0s 218us/step - loss: 15.2418\n",
      "Epoch 262/300\n",
      "939/939 [==============================] - 0s 219us/step - loss: 15.2404\n",
      "Epoch 263/300\n",
      "939/939 [==============================] - 0s 327us/step - loss: 15.2409\n",
      "Epoch 264/300\n",
      "939/939 [==============================] - 0s 290us/step - loss: 15.2396\n",
      "Epoch 265/300\n",
      "939/939 [==============================] - 0s 217us/step - loss: 15.2414\n",
      "Epoch 266/300\n",
      "939/939 [==============================] - 0s 221us/step - loss: 15.2411\n",
      "Epoch 267/300\n",
      "939/939 [==============================] - 0s 259us/step - loss: 15.2429\n",
      "Epoch 268/300\n",
      "939/939 [==============================] - 0s 330us/step - loss: 15.2428\n",
      "Epoch 269/300\n",
      "939/939 [==============================] - 0s 283us/step - loss: 15.2428\n",
      "Epoch 270/300\n",
      "939/939 [==============================] - 0s 216us/step - loss: 15.2435\n",
      "Epoch 271/300\n",
      "939/939 [==============================] - 0s 239us/step - loss: 15.2434\n",
      "Epoch 272/300\n",
      "939/939 [==============================] - 0s 284us/step - loss: 15.2401\n",
      "Epoch 273/300\n",
      "939/939 [==============================] - 0s 218us/step - loss: 15.2408\n",
      "Epoch 274/300\n",
      "939/939 [==============================] - 0s 216us/step - loss: 15.2414\n",
      "Epoch 275/300\n",
      "939/939 [==============================] - 0s 219us/step - loss: 15.2392\n",
      "Epoch 276/300\n",
      "939/939 [==============================] - 0s 216us/step - loss: 15.2398\n",
      "Epoch 277/300\n",
      "939/939 [==============================] - 0s 216us/step - loss: 15.2433\n",
      "Epoch 278/300\n",
      "939/939 [==============================] - 0s 223us/step - loss: 15.2449\n",
      "Epoch 279/300\n",
      "939/939 [==============================] - 0s 345us/step - loss: 15.2436\n",
      "Epoch 280/300\n",
      "939/939 [==============================] - 0s 265us/step - loss: 15.2437\n",
      "Epoch 281/300\n",
      "939/939 [==============================] - 0s 241us/step - loss: 15.2420\n",
      "Epoch 282/300\n",
      "939/939 [==============================] - 0s 283us/step - loss: 15.2396\n",
      "Epoch 283/300\n",
      "939/939 [==============================] - 0s 221us/step - loss: 15.2397\n",
      "Epoch 284/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "939/939 [==============================] - 0s 220us/step - loss: 15.2497\n",
      "Epoch 285/300\n",
      "939/939 [==============================] - 0s 225us/step - loss: 15.2570\n",
      "Epoch 286/300\n",
      "939/939 [==============================] - 0s 227us/step - loss: 15.2473\n",
      "Epoch 287/300\n",
      "939/939 [==============================] - 0s 214us/step - loss: 15.2456\n",
      "Epoch 288/300\n",
      "939/939 [==============================] - 0s 211us/step - loss: 15.2413\n",
      "Epoch 289/300\n",
      "939/939 [==============================] - 0s 215us/step - loss: 15.2392\n",
      "Epoch 290/300\n",
      "939/939 [==============================] - 0s 213us/step - loss: 15.2400\n",
      "Epoch 291/300\n",
      "939/939 [==============================] - 0s 214us/step - loss: 15.2385\n",
      "Epoch 292/300\n",
      "939/939 [==============================] - 0s 212us/step - loss: 15.2393\n",
      "Epoch 293/300\n",
      "939/939 [==============================] - 0s 216us/step - loss: 15.2375\n",
      "Epoch 294/300\n",
      "939/939 [==============================] - 0s 217us/step - loss: 15.2366\n",
      "Epoch 295/300\n",
      "939/939 [==============================] - 0s 221us/step - loss: 15.2384\n",
      "Epoch 296/300\n",
      "939/939 [==============================] - 0s 326us/step - loss: 15.2368\n",
      "Epoch 297/300\n",
      "939/939 [==============================] - 0s 318us/step - loss: 15.2360\n",
      "Epoch 298/300\n",
      "939/939 [==============================] - 0s 276us/step - loss: 15.2362\n",
      "Epoch 299/300\n",
      "939/939 [==============================] - 0s 220us/step - loss: 15.2362\n",
      "Epoch 300/300\n",
      "939/939 [==============================] - 0s 218us/step - loss: 15.2386\n",
      "234/234 [==============================] - 0s 2ms/step\n",
      "2.6620389885372586\n"
     ]
    }
   ],
   "source": [
    "class AutoEncoder:\n",
    "    def __init__(self, encoding_dim):\n",
    "        self.encoding_dim = encoding_dim\n",
    "\n",
    "    def build_train_model(self, input_shape, encoded1_shape, encoded2_shape, decoded1_shape, decoded2_shape):\n",
    "        input_data = Input(shape=(1, input_shape))\n",
    "\n",
    "        encoded1 = Dense(encoded1_shape, activation=\"relu\", activity_regularizer=regularizers.l2(0))(input_data)\n",
    "        encoded2 = Dense(encoded2_shape, activation=\"relu\", activity_regularizer=regularizers.l2(0))(encoded1)\n",
    "        encoded3 = Dense(self.encoding_dim, activation=\"relu\", activity_regularizer=regularizers.l2(0))(encoded2)\n",
    "        decoded1 = Dense(decoded1_shape, activation=\"relu\", activity_regularizer=regularizers.l2(0))(encoded3)\n",
    "        decoded2 = Dense(decoded2_shape, activation=\"relu\", activity_regularizer=regularizers.l2(0))(decoded1)\n",
    "        decoded = Dense(input_shape, activation=\"sigmoid\", activity_regularizer=regularizers.l2(0))(decoded2)\n",
    "\n",
    "        autoencoder = Model(inputs=input_data, outputs=decoded)\n",
    "\n",
    "        encoder = Model(input_data, encoded3)\n",
    "\n",
    "        # Now train the model using data we already preprocessed\n",
    "        autoencoder.compile(loss=\"mean_squared_error\", optimizer=\"adam\")\n",
    "\n",
    "        train = pd.read_csv(\"preprocessing/rbm_train.csv\", index_col=0)\n",
    "        ntrain = np.array(train)\n",
    "        train_data = np.reshape(ntrain, (len(ntrain), 1, input_shape))\n",
    "\n",
    "        # print(train_data)\n",
    "        # autoencoder.summary()\n",
    "        autoencoder.fit(train_data, train_data, epochs=300)\n",
    "\n",
    "        encoder.save(\"models/encoder.h5\")\n",
    "\n",
    "        test = pd.read_csv(\"preprocessing/rbm_test.csv\", index_col=0)\n",
    "        ntest = np.array(test)\n",
    "        test_data = np.reshape(ntest, (len(ntest), 1, 55))\n",
    "\n",
    "        print(autoencoder.evaluate(test_data, test_data))\n",
    "        # pred = np.reshape(ntest[1], (1, 1, 75))\n",
    "        # print(encoder.predict(pred))\n",
    "\n",
    "        log_train = pd.read_csv(\"preprocessing/log_train.csv\", index_col=0)\n",
    "        coded_train = []\n",
    "        for i in range(len(log_train)):\n",
    "            data = np.array(log_train.iloc[i, :])\n",
    "            values = np.reshape(data, (1, 1, 55))\n",
    "            coded = encoder.predict(values)\n",
    "            shaped = np.reshape(coded, (20,))\n",
    "            coded_train.append(shaped)\n",
    "\n",
    "        train_coded = pd.DataFrame(coded_train)\n",
    "        train_coded.to_csv(\"features/autoencoded_data.csv\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    autoencoder = AutoEncoder(20)\n",
    "    autoencoder.build_train_model(55, 40, 30, 30, 40)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataProcessing:\n",
    "    def __init__(self, split, feature_split):\n",
    "        self.split = split\n",
    "        self.feature_split = feature_split\n",
    "        # self.train = pd.read_csv(\"train_data.csv\", index_col=0)\n",
    "        # print(train.tail())\n",
    "        self.test = pd.read_csv(\"preprocessing/test_data.csv\", index_col=0)\n",
    "        # print(test.tail())\n",
    "        self.test_stock = pd.read_csv(\"preprocessing/test_stock.csv\", index_col=0)\n",
    "        # self.auto_train = pd.read_csv(\"features/autoencoded_corrected_data.csv\", index_col=0)\n",
    "        self.auto_train = pd.read_csv(\"features/autoencoded_data.csv\", index_col=0)\n",
    "        # auto_train.drop([0, 14, 16], axis=1, inplace=True)\n",
    "        # auto_train.to_csv(\"autoencoded_corrected_data.csv\", index=None)\n",
    "\n",
    "    def make_train_data(self):\n",
    "        train_data = np.array(self.auto_train)[int(self.feature_split*len(self.auto_train))+1:\n",
    "                                               int((1-self.feature_split)*self.split*len(self.auto_train))]\n",
    "        train_data = pd.DataFrame(train_data, index=None)\n",
    "        train_data.to_csv(\"features/autoencoded_train_data.csv\")\n",
    "\n",
    "    def make_test_data(self):\n",
    "        test_data = np.array(self.auto_train)[int((1-self.feature_split)*self.split*len(self.auto_train) +\n",
    "                                                  self.feature_split*len(self.auto_train)+1):]\n",
    "        test_data = pd.DataFrame(test_data, index=None)\n",
    "        test_data.to_csv(\"features/autoencoded_test_data.csv\")\n",
    "        \n",
    "    def make_train_y(self):\n",
    "        train_y = np.array(self.test)[int(self.feature_split*len(self.auto_train))+1:\n",
    "                                      int((1-self.feature_split)*self.split*len(self.auto_train))]\n",
    "        train_y = pd.DataFrame(train_y, index=None)\n",
    "        train_y.to_csv(\"features/autoencoded_train_y.csv\")\n",
    "\n",
    "    def make_test_y(self):\n",
    "        test_y = np.array(self.test)[int((1-self.feature_split)*self.split*len(self.auto_train) +\n",
    "                                         self.feature_split*len(self.auto_train))+1:]\n",
    "        test_y = pd.DataFrame(test_y)\n",
    "        test_y.to_csv(\"features/autoencoded_test_y.csv\")\n",
    "\n",
    "    def make_stock_train_y(self):\n",
    "        test_y = np.array(self.test_stock)[int(self.feature_split*len(self.auto_train))+1:\n",
    "                                           int((1-self.feature_split)*self.split*len(self.auto_train))]\n",
    "        test_y = pd.DataFrame(test_y, index=None)\n",
    "        test_y.to_csv(\"features/nn_stock_train_y.csv\")\n",
    "\n",
    "    def make_stock_test_y(self):\n",
    "        test_y = np.array(self.test_stock)[int((1-self.feature_split)*self.split*len(self.auto_train))+1:]\n",
    "        test_y = pd.DataFrame(test_y, index=None)\n",
    "        test_y.to_csv(\"features/nn_stock_test_y.csv\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    process = DataProcessing(0.8, 0.25)\n",
    "    process.make_test_data()\n",
    "    process.make_train_data()\n",
    "    process.make_train_y()\n",
    "    process.make_test_y()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1644/1644 [==============================] - 10s 6ms/step - loss: 6.6499 - mean_squared_error: 6.4317\n",
      "Epoch 2/100\n",
      "1644/1644 [==============================] - 1s 559us/step - loss: 6.6226 - mean_squared_error: 6.4241\n",
      "Epoch 3/100\n",
      "1644/1644 [==============================] - 1s 598us/step - loss: 6.6027 - mean_squared_error: 6.4160\n",
      "Epoch 4/100\n",
      "1644/1644 [==============================] - 1s 596us/step - loss: 6.5868 - mean_squared_error: 6.4102\n",
      "Epoch 5/100\n",
      "1644/1644 [==============================] - 1s 545us/step - loss: 6.5707 - mean_squared_error: 6.4028\n",
      "Epoch 6/100\n",
      "1644/1644 [==============================] - 1s 541us/step - loss: 6.5574 - mean_squared_error: 6.3974\n",
      "Epoch 7/100\n",
      "1644/1644 [==============================] - 1s 624us/step - loss: 6.5439 - mean_squared_error: 6.3915\n",
      "Epoch 8/100\n",
      "1644/1644 [==============================] - 1s 630us/step - loss: 6.5295 - mean_squared_error: 6.3840\n",
      "Epoch 9/100\n",
      "1644/1644 [==============================] - 1s 576us/step - loss: 6.5174 - mean_squared_error: 6.3788\n",
      "Epoch 10/100\n",
      "1644/1644 [==============================] - 1s 570us/step - loss: 6.5073 - mean_squared_error: 6.3752\n",
      "Epoch 11/100\n",
      "1644/1644 [==============================] - 1s 547us/step - loss: 6.4990 - mean_squared_error: 6.3725\n",
      "Epoch 12/100\n",
      "1644/1644 [==============================] - 1s 594us/step - loss: 6.4919 - mean_squared_error: 6.3714\n",
      "Epoch 13/100\n",
      "1644/1644 [==============================] - 1s 595us/step - loss: 6.4820 - mean_squared_error: 6.3670\n",
      "Epoch 14/100\n",
      "1644/1644 [==============================] - 1s 555us/step - loss: 6.4709 - mean_squared_error: 6.3611\n",
      "Epoch 15/100\n",
      "1644/1644 [==============================] - 1s 631us/step - loss: 6.4672 - mean_squared_error: 6.3621\n",
      "Epoch 16/100\n",
      "1644/1644 [==============================] - 1s 581us/step - loss: 6.4593 - mean_squared_error: 6.3589\n",
      "Epoch 17/100\n",
      "1644/1644 [==============================] - 1s 554us/step - loss: 6.4529 - mean_squared_error: 6.3572\n",
      "Epoch 18/100\n",
      "1644/1644 [==============================] - 1s 587us/step - loss: 6.4483 - mean_squared_error: 6.3568\n",
      "Epoch 19/100\n",
      "1644/1644 [==============================] - 1s 558us/step - loss: 6.4427 - mean_squared_error: 6.3554\n",
      "Epoch 20/100\n",
      "1644/1644 [==============================] - 1s 547us/step - loss: 6.4378 - mean_squared_error: 6.3541\n",
      "Epoch 21/100\n",
      "1644/1644 [==============================] - 1s 599us/step - loss: 6.4312 - mean_squared_error: 6.3510\n",
      "Epoch 22/100\n",
      "1644/1644 [==============================] - 1s 574us/step - loss: 6.4275 - mean_squared_error: 6.3508\n",
      "Epoch 23/100\n",
      "1644/1644 [==============================] - 1s 544us/step - loss: 6.4209 - mean_squared_error: 6.3469\n",
      "Epoch 24/100\n",
      "1644/1644 [==============================] - 1s 547us/step - loss: 6.4191 - mean_squared_error: 6.3486\n",
      "Epoch 25/100\n",
      "1644/1644 [==============================] - 1s 540us/step - loss: 6.4145 - mean_squared_error: 6.3469\n",
      "Epoch 26/100\n",
      "1644/1644 [==============================] - 1s 599us/step - loss: 6.4125 - mean_squared_error: 6.3474\n",
      "Epoch 27/100\n",
      "1644/1644 [==============================] - 1s 587us/step - loss: 6.4057 - mean_squared_error: 6.3436\n",
      "Epoch 28/100\n",
      "1644/1644 [==============================] - 1s 570us/step - loss: 6.4059 - mean_squared_error: 6.3463\n",
      "Epoch 29/100\n",
      "1644/1644 [==============================] - 1s 561us/step - loss: 6.4016 - mean_squared_error: 6.3446\n",
      "Epoch 30/100\n",
      "1644/1644 [==============================] - 1s 597us/step - loss: 6.3992 - mean_squared_error: 6.3443\n",
      "Epoch 31/100\n",
      "1644/1644 [==============================] - 1s 588us/step - loss: 6.3973 - mean_squared_error: 6.3448\n",
      "Epoch 32/100\n",
      "1644/1644 [==============================] - 1s 555us/step - loss: 6.3926 - mean_squared_error: 6.3420\n",
      "Epoch 33/100\n",
      "1644/1644 [==============================] - 1s 549us/step - loss: 6.3905 - mean_squared_error: 6.3416\n",
      "Epoch 34/100\n",
      "1644/1644 [==============================] - 1s 600us/step - loss: 6.3885 - mean_squared_error: 6.3417\n",
      "Epoch 35/100\n",
      "1644/1644 [==============================] - 1s 618us/step - loss: 6.3858 - mean_squared_error: 6.3413\n",
      "Epoch 36/100\n",
      "1644/1644 [==============================] - 1s 592us/step - loss: 6.3846 - mean_squared_error: 6.3414\n",
      "Epoch 37/100\n",
      "1644/1644 [==============================] - 1s 584us/step - loss: 6.3804 - mean_squared_error: 6.3388\n",
      "Epoch 38/100\n",
      "1644/1644 [==============================] - 1s 606us/step - loss: 6.3796 - mean_squared_error: 6.3394\n",
      "Epoch 39/100\n",
      "1644/1644 [==============================] - 1s 557us/step - loss: 6.3776 - mean_squared_error: 6.3388\n",
      "Epoch 40/100\n",
      "1644/1644 [==============================] - 1s 631us/step - loss: 6.3760 - mean_squared_error: 6.3386\n",
      "Epoch 41/100\n",
      "1644/1644 [==============================] - 1s 713us/step - loss: 6.3732 - mean_squared_error: 6.3370\n",
      "Epoch 42/100\n",
      "1644/1644 [==============================] - 1s 622us/step - loss: 6.3736 - mean_squared_error: 6.3386\n",
      "Epoch 43/100\n",
      "1644/1644 [==============================] - 1s 562us/step - loss: 6.3710 - mean_squared_error: 6.3372\n",
      "Epoch 44/100\n",
      "1644/1644 [==============================] - 1s 560us/step - loss: 6.3710 - mean_squared_error: 6.3384\n",
      "Epoch 45/100\n",
      "1644/1644 [==============================] - 1s 569us/step - loss: 6.3690 - mean_squared_error: 6.3375\n",
      "Epoch 46/100\n",
      "1644/1644 [==============================] - 1s 589us/step - loss: 6.3676 - mean_squared_error: 6.3371\n",
      "Epoch 47/100\n",
      "1644/1644 [==============================] - 1s 586us/step - loss: 6.3668 - mean_squared_error: 6.3374\n",
      "Epoch 48/100\n",
      "1644/1644 [==============================] - 1s 575us/step - loss: 6.3655 - mean_squared_error: 6.3372\n",
      "Epoch 49/100\n",
      "1644/1644 [==============================] - 1s 541us/step - loss: 6.3627 - mean_squared_error: 6.3351\n",
      "Epoch 50/100\n",
      "1644/1644 [==============================] - 1s 541us/step - loss: 6.3615 - mean_squared_error: 6.3348\n",
      "Epoch 51/100\n",
      "1644/1644 [==============================] - 1s 545us/step - loss: 6.3626 - mean_squared_error: 6.3368\n",
      "Epoch 52/100\n",
      "1644/1644 [==============================] - 1s 543us/step - loss: 6.3612 - mean_squared_error: 6.3365\n",
      "Epoch 53/100\n",
      "1644/1644 [==============================] - 1s 542us/step - loss: 6.3600 - mean_squared_error: 6.3358\n",
      "Epoch 54/100\n",
      "1644/1644 [==============================] - 1s 545us/step - loss: 6.3574 - mean_squared_error: 6.3339\n",
      "Epoch 55/100\n",
      "1644/1644 [==============================] - 1s 544us/step - loss: 6.3574 - mean_squared_error: 6.3345\n",
      "Epoch 56/100\n",
      "1644/1644 [==============================] - 1s 544us/step - loss: 6.3566 - mean_squared_error: 6.3343\n",
      "Epoch 57/100\n",
      "1644/1644 [==============================] - 1s 577us/step - loss: 6.3560 - mean_squared_error: 6.3344\n",
      "Epoch 58/100\n",
      "1644/1644 [==============================] - 1s 569us/step - loss: 6.3557 - mean_squared_error: 6.3347\n",
      "Epoch 59/100\n",
      "1644/1644 [==============================] - 1s 538us/step - loss: 6.3547 - mean_squared_error: 6.3343\n",
      "Epoch 60/100\n",
      "1644/1644 [==============================] - 1s 589us/step - loss: 6.3530 - mean_squared_error: 6.3332\n",
      "Epoch 61/100\n",
      "1644/1644 [==============================] - 1s 554us/step - loss: 6.3532 - mean_squared_error: 6.3339\n",
      "Epoch 62/100\n",
      "1644/1644 [==============================] - 1s 546us/step - loss: 6.3524 - mean_squared_error: 6.3337\n",
      "Epoch 63/100\n",
      "1644/1644 [==============================] - 1s 544us/step - loss: 6.3519 - mean_squared_error: 6.3337\n",
      "Epoch 64/100\n",
      "1644/1644 [==============================] - 1s 544us/step - loss: 6.3513 - mean_squared_error: 6.3335\n",
      "Epoch 65/100\n",
      "1644/1644 [==============================] - 1s 541us/step - loss: 6.3507 - mean_squared_error: 6.3336\n",
      "Epoch 66/100\n",
      "1644/1644 [==============================] - 1s 549us/step - loss: 6.3501 - mean_squared_error: 6.3334\n",
      "Epoch 67/100\n",
      "1644/1644 [==============================] - 1s 547us/step - loss: 6.3496 - mean_squared_error: 6.3334\n",
      "Epoch 68/100\n",
      "1644/1644 [==============================] - 1s 566us/step - loss: 6.3498 - mean_squared_error: 6.3342\n",
      "Epoch 69/100\n",
      "1644/1644 [==============================] - 1s 569us/step - loss: 6.3487 - mean_squared_error: 6.3335\n",
      "Epoch 70/100\n",
      "1644/1644 [==============================] - 1s 579us/step - loss: 6.3484 - mean_squared_error: 6.3336\n",
      "Epoch 71/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1644/1644 [==============================] - 1s 568us/step - loss: 6.3487 - mean_squared_error: 6.3342\n",
      "Epoch 72/100\n",
      "1644/1644 [==============================] - 1s 562us/step - loss: 6.3468 - mean_squared_error: 6.3327\n",
      "Epoch 73/100\n",
      "1644/1644 [==============================] - 1s 623us/step - loss: 6.3469 - mean_squared_error: 6.3332\n",
      "Epoch 74/100\n",
      "1644/1644 [==============================] - 1s 561us/step - loss: 6.3464 - mean_squared_error: 6.3330\n",
      "Epoch 75/100\n",
      "1644/1644 [==============================] - 1s 586us/step - loss: 6.3460 - mean_squared_error: 6.3329\n",
      "Epoch 76/100\n",
      "1644/1644 [==============================] - 1s 563us/step - loss: 6.3453 - mean_squared_error: 6.3326\n",
      "Epoch 77/100\n",
      "1644/1644 [==============================] - 1s 536us/step - loss: 6.3438 - mean_squared_error: 6.3314\n",
      "Epoch 78/100\n",
      "1644/1644 [==============================] - 1s 535us/step - loss: 6.3438 - mean_squared_error: 6.3317\n",
      "Epoch 79/100\n",
      "1644/1644 [==============================] - 1s 543us/step - loss: 6.3433 - mean_squared_error: 6.3315\n",
      "Epoch 80/100\n",
      "1644/1644 [==============================] - 1s 545us/step - loss: 6.3440 - mean_squared_error: 6.3326\n",
      "Epoch 81/100\n",
      "1644/1644 [==============================] - 1s 536us/step - loss: 6.3434 - mean_squared_error: 6.3322\n",
      "Epoch 82/100\n",
      "1644/1644 [==============================] - 1s 536us/step - loss: 6.3435 - mean_squared_error: 6.3327\n",
      "Epoch 83/100\n",
      "1644/1644 [==============================] - 1s 541us/step - loss: 6.3425 - mean_squared_error: 6.3318\n",
      "Epoch 84/100\n",
      "1644/1644 [==============================] - 1s 671us/step - loss: 6.3423 - mean_squared_error: 6.3318\n",
      "Epoch 85/100\n",
      "1644/1644 [==============================] - 1s 565us/step - loss: 6.3424 - mean_squared_error: 6.3322\n",
      "Epoch 86/100\n",
      "1644/1644 [==============================] - 1s 550us/step - loss: 6.3416 - mean_squared_error: 6.3317\n",
      "Epoch 87/100\n",
      "1644/1644 [==============================] - 1s 551us/step - loss: 6.3415 - mean_squared_error: 6.3318\n",
      "Epoch 88/100\n",
      "1644/1644 [==============================] - 1s 566us/step - loss: 6.3413 - mean_squared_error: 6.3320\n",
      "Epoch 89/100\n",
      "1644/1644 [==============================] - 1s 560us/step - loss: 6.3409 - mean_squared_error: 6.3317\n",
      "Epoch 90/100\n",
      "1644/1644 [==============================] - 1s 537us/step - loss: 6.3405 - mean_squared_error: 6.3315\n",
      "Epoch 91/100\n",
      "1644/1644 [==============================] - 1s 537us/step - loss: 6.3405 - mean_squared_error: 6.3317\n",
      "Epoch 92/100\n",
      "1644/1644 [==============================] - 1s 540us/step - loss: 6.3401 - mean_squared_error: 6.3314\n",
      "Epoch 93/100\n",
      "1644/1644 [==============================] - 1s 656us/step - loss: 6.3400 - mean_squared_error: 6.3315\n",
      "Epoch 94/100\n",
      "1644/1644 [==============================] - 1s 588us/step - loss: 6.3398 - mean_squared_error: 6.3316\n",
      "Epoch 95/100\n",
      "1644/1644 [==============================] - 1s 606us/step - loss: 6.3388 - mean_squared_error: 6.3308\n",
      "Epoch 96/100\n",
      "1644/1644 [==============================] - 1s 590us/step - loss: 6.3389 - mean_squared_error: 6.3310\n",
      "Epoch 97/100\n",
      "1644/1644 [==============================] - 1s 649us/step - loss: 6.3389 - mean_squared_error: 6.3311\n",
      "Epoch 98/100\n",
      "1644/1644 [==============================] - 1s 664us/step - loss: 6.3380 - mean_squared_error: 6.3305\n",
      "Epoch 99/100\n",
      "1644/1644 [==============================] - 1s 588us/step - loss: 6.3380 - mean_squared_error: 6.3306\n",
      "Epoch 100/100\n",
      "1644/1644 [==============================] - 1s 620us/step - loss: 6.3380 - mean_squared_error: 6.3307\n",
      "704/704 [==============================] - 4s 5ms/step\n",
      "[1.858401047912511, 1.8511881598017432]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mac/anaconda3/envs/AI-Test/lib/python3.6/site-packages/ipykernel_launcher.py:44: RuntimeWarning: invalid value encountered in true_divide\n",
      "No handles with labels found to put in legend.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "class NeuralNetwork:\n",
    "    def __init__(self, input_shape, stock_or_return):\n",
    "        self.input_shape = input_shape\n",
    "        self.stock_or_return = stock_or_return\n",
    "\n",
    "    def make_train_model(self):\n",
    "        input_data = kl.Input(shape=(1, self.input_shape))\n",
    "        lstm = kl.LSTM(5, input_shape=(1, self.input_shape), return_sequences=True, activity_regularizer=regularizers.l2(0.003),\n",
    "                       recurrent_regularizer=regularizers.l2(0), dropout=0.2, recurrent_dropout=0.2)(input_data)\n",
    "        perc = kl.Dense(5, activation=\"sigmoid\", activity_regularizer=regularizers.l2(0.005))(lstm)\n",
    "        lstm2 = kl.LSTM(2, activity_regularizer=regularizers.l2(0.01), recurrent_regularizer=regularizers.l2(0.001),\n",
    "                        dropout=0.2, recurrent_dropout=0.2)(perc)\n",
    "        out = kl.Dense(1, activation=\"sigmoid\", activity_regularizer=regularizers.l2(0.001))(lstm2)\n",
    "\n",
    "        model = Model(input_data, out)\n",
    "        model.compile(optimizer=\"adam\", loss=\"mean_squared_error\", metrics=[\"mse\"])\n",
    "\n",
    "        # load data\n",
    "\n",
    "        train = np.reshape(np.array(pd.read_csv(\"features/autoencoded_train_data.csv\", index_col=0)),\n",
    "                           (len(np.array(pd.read_csv(\"features/autoencoded_train_data.csv\"))), 1, self.input_shape))\n",
    "        train_y = np.array(pd.read_csv(\"features/autoencoded_train_y.csv\", index_col=0))\n",
    "        # train_stock = np.array(pd.read_csv(\"train_stock.csv\"))\n",
    "\n",
    "        # train model\n",
    "\n",
    "        model.fit(train, train_y, epochs=100)\n",
    "\n",
    "        model.save(\"models/model.h5\", overwrite=True, include_optimizer=True)\n",
    "\n",
    "        test_x = np.reshape(np.array(pd.read_csv(\"features/autoencoded_test_data.csv\", index_col=0)),\n",
    "                            (len(np.array(pd.read_csv(\"features/autoencoded_test_data.csv\"))), 1, self.input_shape))\n",
    "        test_y = np.array(pd.read_csv(\"features/autoencoded_test_y.csv\", index_col=0))\n",
    "        # test_stock = np.array(pd.read_csv(\"test_stock.csv\"))\n",
    "\n",
    "        stock_data_test = np.array(pd.read_csv(\"stock_data_test.csv\", index_col=0))\n",
    "\n",
    "        print(model.evaluate(test_x, test_y))\n",
    "        prediction_data = []\n",
    "        stock_data = []\n",
    "        for i in range(len(test_y)):\n",
    "            prediction = (model.predict(np.reshape(test_x[i], (1, 1, self.input_shape))))\n",
    "            prediction_data.append(np.reshape(prediction, (1,)))\n",
    "            prediction_corrected = (prediction_data - np.mean(prediction_data))/np.std(prediction_data)\n",
    "            stock_price = np.exp(np.reshape(prediction, (1,)))*stock_data_test[i]\n",
    "            stock_data.append(stock_price[0])\n",
    "        stock_data[:] = [i - (float(stock_data[0])-float(stock_data_test[0])) for i in stock_data]\n",
    "        # stock_data = stock_data - stock_data[0]\n",
    "        if self.stock_or_return:\n",
    "            plt.plot(stock_data)\n",
    "            plt.plot(stock_data_test)\n",
    "            stock = pd.DataFrame(stock_data, index=None)\n",
    "            stock.to_csv(\"sample_predictions/AAPL_predicted_prices.csv\")\n",
    "            stock_test = pd.DataFrame(stock_data_test, index=None)\n",
    "            stock_test.to_csv(\"sample_predictions/AAPL_actual_prices.csv\")\n",
    "            # print(stock_data)\n",
    "            plt.legend()\n",
    "            plt.show()\n",
    "        else:\n",
    "            # plt.plot(prediction_corrected)\n",
    "            plt.plot(prediction_data)\n",
    "            # print(prediction_data)\n",
    "            plt.plot(test_y)\n",
    "            plt.legend()\n",
    "            plt.show()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    model = NeuralNetwork(20, True)\n",
    "    model.make_train_model()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] File b'60_return_forex/encoded_return_train_data.csv' does not exist: b'60_return_forex/encoded_return_train_data.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-198349869cf0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m     \u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnnmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.05\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.01\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Price Accuracy Average = {average} \\nPrice Accuracy Standard Deviation = {std}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-198349869cf0>\u001b[0m in \u001b[0;36mnnmodel\u001b[0;34m(epochs, regularizer1, regularizer2)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mnnmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mregularizer1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mregularizer2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mtrain_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"60_return_forex/encoded_return_train_data.csv\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex_col\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0;31m# length = len(train_data)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mtrain_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/AI-Test/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    700\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[1;32m    701\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 702\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    703\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/AI-Test/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    427\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    428\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 429\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    430\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    431\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/AI-Test/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/AI-Test/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1120\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'c'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1121\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'c'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1122\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1123\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1124\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'python'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/AI-Test/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1851\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'usecols'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1852\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1853\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1854\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1855\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] File b'60_return_forex/encoded_return_train_data.csv' does not exist: b'60_return_forex/encoded_return_train_data.csv'"
     ]
    }
   ],
   "source": [
    "def nnmodel(epochs, regularizer1, regularizer2):\n",
    "\n",
    "    train_data = np.array(pd.read_csv(\"60_return_forex/encoded_return_train_data.csv\", index_col=0))\n",
    "    # length = len(train_data)\n",
    "    train_data = np.reshape(train_data, (len(train_data), 20))\n",
    "    print(np.shape(train_data))\n",
    "    test_data = np.array(pd.read_csv(\"60_return_forex/encoded_return_test_data.csv\", index_col=0))\n",
    "    test_data = np.reshape(test_data, (len(test_data), 20))\n",
    "    train_y = np.array(pd.read_csv(\"forex_y/log_train_y.csv\", index_col=0))\n",
    "    test_y = np.array(pd.read_csv(\"forex_y/log_test_y.csv\", index_col=0))\n",
    "    price = np.array(pd.read_csv(\"forex_y/test_price.csv\", index_col=0))\n",
    "\n",
    "    model = kr.models.Sequential()\n",
    "    # model.add(kl.Dense(50, activation=\"sigmoid\", activity_regularizer=kr.regularizers.l2(0)))\n",
    "    model.add(kl.Dense(20, input_dim=20, activation=\"tanh\", activity_regularizer=kr.regularizers.l2(regularizer1)))\n",
    "    model.add(kl.Dense(20, activation=\"tanh\", activity_regularizer=kr.regularizers.l2(regularizer2)))\n",
    "    # model.add(kl.Dense(100))\n",
    "    model.add(kl.Dense(1))\n",
    "\n",
    "    model.compile(optimizer=\"sgd\", loss=\"mean_squared_error\")\n",
    "    model.fit(train_data, train_y, epochs=epochs)\n",
    "    model.save(\"models/final_model.h5\")\n",
    "    predicted_data = []\n",
    "    predicted_price = []\n",
    "    for i in range(len(test_data)):\n",
    "        prediction = model.predict(np.reshape(test_data[i], (1, 20)))\n",
    "        predicted_data.append(prediction)\n",
    "        price_pred = np.exp(prediction)*price[i]\n",
    "        predicted_price.append(price_pred)\n",
    "        # print(test_data[i])\n",
    "\n",
    "    # print(model.evaluate(test_data, test_y))\n",
    "    pd.DataFrame(np.reshape(predicted_price, (len(predicted_price, )))).to_csv(\"60_return_forex/predicted_price.csv\")\n",
    "    pd.DataFrame(price).to_csv(\"60_return_forex/price.csv\")\n",
    "\n",
    "    plt.figure(1)\n",
    "    plt.subplot(2, 1, 1)\n",
    "    plt.plot(np.arange(len(predicted_data)), np.reshape(test_y, (len(test_y))),\n",
    "             np.reshape(predicted_data, (len(predicted_data))))\n",
    "    plt.title(\"Prediction vs Actual\")\n",
    "    plt.ylabel(\"Log Return\")\n",
    "\n",
    "    plt.subplot(2, 1, 2)\n",
    "    plt.plot(np.arange(len(predicted_price)), np.reshape(price, (len(price))),\n",
    "             np.reshape(predicted_price, (len(predicted_price))))\n",
    "    plt.xlabel(\"Time stamp\")\n",
    "    plt.ylabel(\"Market Price\")\n",
    "    plt.show()\n",
    "\n",
    "    price_r_score = r2_score(np.reshape(predicted_price, (len(predicted_price))), price)\n",
    "    return_r_score = r2_score(np.reshape(predicted_data, (len(predicted_data))), test_y)\n",
    "    price_mse = mean_squared_error(np.reshape(predicted_price, (len(predicted_price))), price)\n",
    "    return_mse = mean_squared_error(np.reshape(predicted_data, (len(predicted_data))), test_y)\n",
    "\n",
    "    print(f\"Regularizer for 1: {regularizer1} \\nRegularizer for 2: {regularizer2} \\nEpochs: {epochs}\")\n",
    "    print(f\"Predicted Price r^2 value: {price_r_score} \\nPredicted return r^2 value: {return_r_score}\"\n",
    "          f\"\\nPredict Price MSE: {price_mse} \\nPredicted Return MSE: {return_mse}\")\n",
    "    dataset = []\n",
    "    values = np.array([regularizer1, regularizer2, epochs, price_r_score, return_r_score, price_mse, return_mse])\n",
    "    dataset.append(values)\n",
    "    dataset = pd.DataFrame(dataset, columns=[\"regularizer1\", \"regularizer2\", \"epochs\", \"price_r_score\", \"return_r_score\", \"price_mse\", \"return_mse\"])\n",
    "    # print(dataset)\n",
    "    accuracy = []\n",
    "    for i in range(len(price)-1):\n",
    "        acc = 100 - (np.abs(predicted_price[i] - price[i+1]))/price[i+1] * 100\n",
    "        accuracy.append(acc)\n",
    "    average = np.mean(accuracy)\n",
    "    std = np.std(accuracy)\n",
    "    ret_acc = []\n",
    "    for i in range(len(test_y)-1):\n",
    "        if test_y[i] != 0:\n",
    "            acc = 100 - (np.abs(predicted_data[i] - test_y[i]))/test_y[i] * 100\n",
    "            ret_acc.append(acc)\n",
    "    ret_avg = np.mean(ret_acc)\n",
    "    ret_std = np.std(ret_acc)\n",
    "    pd.DataFrame(np.reshape(ret_acc, (len(ret_acc, )))).to_csv(\"60_return_forex/ret_acc.csv\")\n",
    "    prediction = np.exp(model.predict(np.reshape(test_data[-2], (1, 20))))*price[-2]\n",
    "    print(prediction)\n",
    "\n",
    "    return dataset, average, std\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    dataset, average, std = nnmodel(500, 0.05, 0.01)\n",
    "    print(f\"Price Accuracy Average = {average} \\nPrice Accuracy Standard Deviation = {std}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
